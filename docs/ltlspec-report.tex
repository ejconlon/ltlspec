\documentclass[format=acmsmall, nonacm=true, review=true, screen=true]{acmart}

\usepackage[utf8]{inputenc}
\usepackage{xcolor}
\usepackage{fancyvrb}
\usepackage{minted}
\usepackage{xspace}
\usepackage{hyperref}

% Use this instead of caption to remove acmart description warnings
\newcommand{\mycaption}[1]{\Description{#1}\caption{#1}}

% Project name
\newcommand{\ltlspec}{\textit{LTLSpec}\xspace}

% For highlighting some texts
\newcommand{\red}[1]{\textcolor{red}{#1}}

% This appears to fix some font problem...
\DeclareRobustCommand{\ttfamily}{\fontencoding{T1}\fontfamily{lmtt}\selectfont}

% Junk for acmart:
\setcopyright{acmcopyright}
\copyrightyear{2021}
\acmYear{2021}
\acmDOI{N/A}
\acmBooktitle{N/A}

\title{LTLSpec: An Extensible LTL Verifier for Distributed Systems}
\subtitle{CPSC 538B Final Project Report, 2021 Winter Term 1}
\author{Eric Conlon}
\author{Yanze Li}
\author{Tarcisio Teixeira}
\authorsaddresses{}
\date{2021-12-07}

\begin{document}

\begin{abstract}
  Specifying and proving properties about distributed systems is difficult enough that often it's not attempted even when it's needed!
  One tractable method is runtime verification, which settles for proofs of invariants over observed traces.
  In this project, we develop \ltlspec, a runtime verification framework that allows users to model system properties in Linear Temporal Logic (LTL).
  Given this, our framework provides a simple LTL verifier for use as an online monitor or offline trace analyzer.
  To address the issue that LTL only has meaning on infinite traces, we introduce a simple mechanism called \textit{truncation} that allows users to exploit known interpretations of quantifiers and atomic propositions after traces end.
  To evaluate \ltlspec, we implement three actor-based distributed systems with corresponding specifications. \ltlspec successfully verifies specified properties for all three systems.
\end{abstract}

\maketitle

\section{Introduction}

Proving that a distributed system operates as intended generally requires modeling the system in a formal framework equipped with its own reasoning techniques.
At one extreme of this design space, one formally specifies the program in full in exchange for strong guarantees about its behavior in all possible executions.
At another extreme, one “merely” specifies formal properties about the observable effects of the program, only able to guarantee that these properties have not been violated in observed executions.
In this project, we use the latter strategy, runtime verification, as a relatively lightweight way to explore “responsiveness properties” of actor-based distributed systems.

We define responsiveness properties following \cite{actorservice,parthasarathy2018modular} as a kind of liveness property of the form \(\Box \forall n. (P(n) \rightarrow \Diamond Q(n))\).
As an example in plain English: “When I send a certain request, I eventually get a response to that particular request.” Propositions with this structure allow one to establish domain-specific causal relations more useful than the “happens-before” of logical time.
In general, one uses a temporal logic to express these propositions. Linear Temporal Logic (LTL), with the \textit{Always} and \textit{Eventually} operators used above, is a popular choice. However, most presentations of LTL apply it to domains only with the use of atomic propositions. One cannot express dependency between these propositions as would be necessary to encode the notion of responsiveness.

As a result, some researchers have introduced first order quantifiers for data variables \cite{khoury_automata-based_2021,margaria_execution_2016,halle_runtime_2012} in systems such as LTL-FO+.
However, in an effort to increase the usefulness and applicability of the logic, we follow a slightly different path through the design space to leave the domain of quantification abstract and not internalize equality on quantified variables.

We have built a runtime verification framework with data variable quantification, decoupled from any particular domain one would verify.
In this paper, we:
\begin{itemize}
  \item Define the \textit{theory} of a distributed system, based on the concept of a first-order logical \textit{theory} of a domain
  \item Define \textit{bridge} interfaces related to each theory that allow the verifier to quantify over data variables and verify inhabitance of atomic propositions from the domain
  \item Implement an LTL \textit{verifiers} to check axioms from the theory against monitored programs and traces
  \item Introduce the \textit{truncation} mechanism to yield more meaningful results against finite traces
  \item Evaluate the effectiveness of \ltlspec on both three distributed system examples
\end{itemize}

\section{Background}
\subsection{Runtime Verification}
Runtime verification (RV), sometimes also referred to as runtime monitoring, trace analysis, or dynamic analysis, is a lightweight formal method that, instead of exhaustively analyzing all possible program executions, only verifies the specified properties based on the current execution trace. Though limited by traces, RV can scale well and be practically integrated with existing complex systems. Moreover, it provides the most precise information regarding the current execution. Typical usage of RV includes checking the correctness of runtime behavior, detecting bugs exhibited at runtime, and enforcing runtime invariants on live systems.

Several types of monitoring methodologies are found in the current literature, \red{!REF HERE!} different approaches may vary a lot in terms of interaction with the system under verification. On one extreme we have offline monitors verifying the execution trace much later it is produced whereas some online monitors may verify the trace along with the system execution. Different approaches result in different concerns, while more intrusive strategies allow early detection and even repair at runtime, offline monitors do verification at almost no overhead for the system.

Nowadays, distributed systems are ubiquitous and complex, and they suffer malfunctions for many reasons. It is desirable to monitor their correct behaviors at runtime, ensuring various safety and liveness guarantees. However, distributed systems pose new challenges to RV. The monitors need to be distributed and coordinate the distributed logs. An expressive enough specification language is also needed to describe the reactive and asynchronous nature of the system.

\subsection{LTL and LTL-FO+}
Linear Temporal Logic (LTL) is a commonly used specification language in formal methods to express properties in reactive and concurrent systems. The basic building blocks for LTL are called atomic propositions, which are opaque, domain-specific symbols (like $P$ or $Q$). Atomic propositions can then be connected or negate with standard boolean operators, including $\land$ (and), $\lor$ (or), $\lnot$ (not), and $\Rightarrow$ (implies), following their classical logic meaning. Most importantly, LTL introduces a set of temporal operators. For all propositions $\phi$ and $\psi$,
\begin{itemize}
  \item Operator $\Box$ means ``always'', $\Box \phi$ means that $\phi$ is true in \textit{every} future time step.
  \item Operator $\Diamond$ means ``eventually'', $\Diamond \phi$ means that $\phi$ holds for \textit{some} future time steps.
  \item Operator $\bigcirc$ means ``next'', $\bigcirc \phi$ means that $\phi$ holds for the \textit{next} time step.
  \item Operator $\mathcal{U}$ means ``Until'', $\phi \mathcal{U}\psi$ means that $\phi$ holds for all time steps until at some step $\psi$ holds. $\psi$ must hold at the current step or in the future.
  \item Operator $\mathcal{W}$ means ``Weak Until'', $\phi \mathcal{W}\psi$ means that $\phi$ holds for all time steps until at some step $\psi$ holds. If $\psi$ never holds, then $\phi$ must hold forever.
\end{itemize}

To achieve stronger expressiveness, different extensions of LTL are proposed. Early work by Emerson \cite{emerson1990temporal} extended LTL with standard first order quantifiers, where the variables are quantified over a fixed domain. A different approach, inspired by the database community, quantifies the variables over a dynamic domain, i.e., variables appear in the trace. The latter is more favorable for RV, since the dynamic domain is more tractable algorithmically. Hence, in our project, we decided to use an LTL extension called LTL-FO+.

LTL-FO+ allows users to quantify over the values seen at the current time step. Given a parameter identifier $p$ and a proposition $\phi$, then $\exists_{p} x : \phi$ and $\forall_{p} x:\phi$ are also propositions. Assume $\rho$ is the trace of the system at the current time (i.e. a \textit{world} in the Kripke sense), then the semantics of the quantifiers can be formalized as below:

$$\rho\vDash \exists_p x:\phi \Leftrightarrow \phi[b/x] \text{for some }b\in Dom_{\rho}(p)$$
$$\forall_{p} x : \phi \equiv \lnot(\exists_{p}x: \lnot\phi)$$

Note that the domain we quantify over is a function of the parameter identifier and the trace at the current time.

For example, let's assume that one wants to check if the property “At some point in the system there exists one value $v$ such that some atomic proposition $\phi(v)$ holds” is satisfied at the current time. Then, using LTL-FO+ we would write the above as follows:

$$ \rho \vDash \Diamond(\exists_{p} v :\phi(v)) $$

The quantifier in LTL-FO+ only quantifies over data variables, therefore it cannot express propositions that quantifies over time. Since it is based on first order logic, it also disallows quantification over things like properties.

\section{LTLSpec}

\begin{figure}[h]
  \includegraphics[width=0.6\textwidth]{images/ltlspec-overview.pdf}
  \centering
  \mycaption{Overview of LTLSpec}
  \label{fig:overview}
\end{figure}

\ltlspec is a verification framework aiming at providing a canonical way for specifying arbitrary first-order LTL properties in distributed system.
Figure~\ref{fig:overview} shows the overview of the framework.
At a high level, \ltlspec consists of three components.
The \textit{theory} is a user-defined domain for verification that includes the definitions of \textit{value types}, \textit{atomic propositions}, and \textit{axioms} about the system.
The \textit{bridge} defines how to evaluate quantifiers over value types and atomic propositions in the axioms.
The \textit{LTL verifier} is an interpreter over the LTL abstract syntax tree.
These components will be further explained in following subsections along with our extensions to the bridge (\textit{truncation}).

\subsection{First-order theories}
\label{subsec:theory}

\ltlspec uses \textit{first-order logical theories} to model user domains.
The specific syntax we use for this purpose is DFOL (First Order Logic with Dependent types) \cite{hutchison_first-order_2006}, which allows one to define the types of values in a domain as well as atomic propositions over those values. (This is called a \textit{signature}.)
Additionally, DFOL allows one to express \textit{axioms} of the system as propositions with quantifiers. Together, the signature and axioms form the theory of the domain. The \textit{dependent} part is a language formality that allows the declaration of propositions indexed by values, as any dependent type system would. This presentation exploits the Curry-Howard correspondence of propositions as types: an axiom's type is a first-order LTL proposition. (In this syntax everything appears as a type declaration without a corresponding definition.) Our LTL verifier interprets these propositions as expressions.

At this time our implementation supports only a subset of possible theories. First, only simple types are supported, meaning there are no type constructors. Second, only simple atomic propositions are supported, meaning these propositions can only take types (not propositions) as arguments. Finally, no value declarations are supported. We made these restrictions to simplify the bridge interface, but future implementations may lift them. Also, at this time we do not parse theories in the textual format presented here, but we do render theory syntax trees this way.

\begin{figure}[h]
  {
    \fontsize{10}{12}\selectfont
    \input{theories/ping.tex}
  }
  \mycaption{Theory for a the ping system}
  \label{fig:ping-theory}
\end{figure}

As an example, consider a simple system in which actors sends a ping messages to a other actors in the system, expecting pong messages as replies.
We want to verify the following responsiveness property: \textit{It is always true that if a node A sends a ping message to node B, then node A will eventually receive a pong message from node B.}

The theory that captures this property is shown in Figure~\ref{fig:ping-theory}. First, we must declare the value types needed for verification. In this case, we are only interested in events related to \textit{ping} and \textit{pong} messages (\texttt{SentPing} and \texttt{RecvPong}).
Second, we need an atomic proposition that checks if a pair of ping-pong messages has the matching sender and receiver (\texttt{isPingPong}).
Finally, the axiom \texttt{isResponsive} can be declared using the value types, atomic propositions, and LTL connectives.

\subsection{Bridge}
\label{subsec:bridge}

The types, propositions, and axioms of a theory characterize a domain but by themselves are not sufficient to verify traces. The user must provide some code we call a \textit{bridge} to interpret those propositions and quantifiers over those types.
Figure~\ref{fig:bridge-sig} presents the typeclass definition for such a component.

\begin{figure}[h]
  {
    \fontsize{10}{12}\selectfont
    \begin{minted}{haskell}
class Eq v => Bridge e v w | w -> e v where
  -- Evaluate the atomic proposition or fail.
  bridgeEvalProp :: w -> Atom v -> Either e Prop
  -- Quantify over all values of the given type or fail.
  bridgeQuantify :: w -> TyName -> Either e [v]
\end{minted}
  }
  \mycaption{Haskell definition of a bridge}
  \label{fig:bridge-sig}
\end{figure}

\texttt{bridgeEvalProp} evaluates an atomic proposition when given correct inputs. It takes the current world \texttt{w} and the atomic proposition \texttt{Atom v} of interest as arguments.
For most bridge definitions, the value of the returned \texttt{Prop} will be either one of the constants between \texttt{PropTrue} and \texttt{PropFalse}.

\texttt{bridgeQuantify} decides how to quantify over a specific type name regarding the current world.
Similarly, it takes the current world \texttt{w} and a type name as arguments and will list of values \texttt{v} of the given type for quantification results.

In our current implementation, there isn't a mechanism to guarantee the correspondence between the theory and the bridge, and it is the user's responsibility to make sure all types and propositions are correctly quantified or evaluated in the bridge. For this reason we allow the bridge to return some user-defined error (the type parameter \texttt{e}) if there are any inconsistencies.
It is possible to provide users with a surface language where the compiler guarantees that a bridge completely interprets its corresponding theory (possibly using code generation), but we consider this future work.

\subsection{LTL verifier}

The LTL verifier operates incrementally over trace elements (i.e. \textit{worlds}), allowing it to be used online as a monitor or offline as a trace analyzer.
For each world, it evaluates each axiom of the theory. Internally, the verifier understands how to interpret standard LTL connectives, but when it encounters a quantifier or atomic proposition it yields the current world and the corresponding quantifier or proposition to the bridge for evaluation.
This interaction continues until the axiom can no longer be evaluated due to error or satisfaction.
Since propositions written in LTL define system properties spanning multiple worlds, there may be residual proof burdens from the current world carried along for further evaluation in the subsequent worlds.

Figure~\ref{fig:verifier-sig} gives the data type definition of \texttt{EnvProp} and the signature of the evaluation function \texttt{envPropEval}.

\begin{figure}[h]
  {
    \fontsize{10}{12}\selectfont
    \begin{minted}{haskell}
-- EnvProp is an LTL proposition with its environment.
data EnvProp v = EnvProp !(Env v) !Prop
-- Evaluates an LTL Proposition based in a given world
envPropEval :: Bridge e v w => EnvProp v -> w -> EnvPropRes e v
\end{minted}
  }
  \mycaption{Haskell definition of the data type \texttt{EnvProp} and the evaluation function}
  \label{fig:verifier-sig}
\end{figure}


\texttt{EnvProp} is a wrapper for primitive LTL propositions \texttt{Prop}.
It carries an additional field \texttt{Env v} that keeps track of the variable bindings introduced by quantifiers from enclosing propositions.

To evaluate an LTL proposition, \texttt{envPropEval} takes an \texttt{EnvProp} and the current world \texttt{w} to compute a result \texttt{EnvPropRes}.
The result is a boolean value when a proposition can be fully evaluated in the current world.
If the proposition involves modal connectives that cannot be evaluated immediately, the result is a residual proposition (possibly composed of logical conjunctions or disjunctions introduced by quantification) that will be carried along to the next world.
If the proposition involves any quantifiers or atomic propositions, the evaluator will invoke the corresponding bridge functions explained in section~\ref{subsec:bridge} using the current world \texttt{w}.

\texttt{envPropEval} only evaluates the LTL proposition on a single world, i.e. one element in the distributed system trace.
To fully verify the system, we call \texttt{envPropEval} iteratively over an entire system trace.
At each iteration, \texttt{envPropEval} takes as arguments a residual proposition along with the current world.

\subsection{Truncation}

One issue for all LTL-based runtime verification techniques is that modal connectives are only meaningful for infinite traces.
In the ping system in subsection~\ref{subsec:theory}, the axiom we want to prove is \texttt{isResponsive}.
This axiom starts with the modal connective ``$\Diamond$ (always)'', meaning that it is a global invariant that holds in \textit{all} future executions.
However, in practice we can only do runtime verification on finite traces, so this axiom can never be proven true but only disproven when a violation is observed.

Such behavior is not always desirable when a system has been monitored for sufficiently long and certain assumptions can be made about its future executions.
To allow users to make assumptions for their systems' behaviors \textit{after} the current traces, we provide a mechanism called \textit{truncation}.

The definition of truncation is essentially an extension to the bridge, as shown in figure~\ref{fig:truncation-sig}.

\begin{figure}[h]
  {
    \fontsize{10}{12}\selectfont
    \begin{minted}{haskell}
-- A 'Bridge' that supports proposition truncation.
class Bridge e v w => TruncBridge e v w where
  -- The set of types with empty quantification in *all reachable worlds*
  truncBridgeEmpty :: w -> Set TyName
  -- An oracle for atomic propositions in *all reachable worlds*
  truncBridgeOracle :: w -> Atom v -> Either e TriBool
\end{minted}
  }
  \mycaption{Haskell definition of a truncation bridge}
  \label{fig:truncation-sig}
\end{figure}

Similar to a bridge, users need to implement two functions that interpret quantifiers and atomic propositions in all reachable worlds (i.e. in all possible traces).
\texttt{truncBridgeEmpty} takes the last world in the trace and decides which set of types now always have empty quantification.
\texttt{truncBridgeOracle} also takes the last world and evaluates atomic propositions that are now constant in all future worlds.
These operations are not arbitrary - they allow bottom up interpretation of a residual proposition in such a way that requires no evaluation under binders nor introduces any additional redexes.

As a result, all propositions will be truncated into a ternary value, namely \textit{true}, \textit{false}, or \textit{unknown}.
For example, propositions that are universally (existentially) quantified over these truncated types will be evaluated to be true (false) while the rest being unknown.
An unknown proposition preserves the original LTL semantics, meaning it has not been disproven up to the point the monitoring ends. But it is unknown whether the proposition will hold in the future.

\section{Evaluation}

We evaluate \ltlspec by verifying three simple distributed systems, i.e. a ping system, a chat system, and an implementation of the dining philosophers problem.

For each example, we can verify its theory according to the collected traces. Detailed implementation and complete for each example is omitted due to page limit.

\subsection{Implementation}

The \ltlspec framework, all example systems, and the corresponding theories and bridges are implemented in Haskell.
The project is open-source and can be found \href{https://github.com/ejconlon/ltlspec}{here}.
We simulate a multinode environment with multithreading and a centralized ``network'' coordinator.
These components use software transactional memory (STM) to preclude unobservable side effects and ensure causal trace collection.
Though we have not implemented it, it is possible to replace the behavior of the network coordinator to inject faults into the system, allowing verification of the system under test in the presence of faults.
We run a global monitor that is able to detect quiesence and terminate the simulation promptly.
Knowing that our simulations go quiescent allows us to implement truncation for these systems.

\subsection{Ping system}

The theory for ping system example has already been presented in Figure~\ref{fig:ping-theory} and Section~\ref{subsec:theory}.

\subsection{Chat system}

We verify correct behavior for a chat room system with a centralized server architecture.
Relevant axioms include message delivery responsiveness (\texttt{ifInChannelReceiveMessage}), persistence of presence in joined rooms (\texttt{isMemberBetweenJoinAndLeave}), and a safety property around never receiving one's own messages (\texttt{neverSendMessageToMyself}). Parts of the theory are presented in Figure~\ref{fig:chat-theory}.

\begin{figure}[ht]
  {
    \fontsize{10}{12}\selectfont
    \input{theories/chat.tex}
  }
  \mycaption{Theory for the chat system}
  \label{fig:chat-theory}
\end{figure}

\subsection{Dining philosophers}

We also simulate the classic concurrency scenario of dining philosophers. Figure~\ref{fig:phil-theory} shows some of the liveness and safety properties we've axiomatized.

\begin{figure}[ht]
  {
    \fontsize{10}{12}\selectfont
    \input{theories/phil.tex}
  }
  \mycaption{Theory for the dining philosophers problem}
  \label{fig:phil-theory}
\end{figure}

\section{Related Work}

Previous work has developed logical frameworks extending separation logic to specify the responsiveness properties in actor-based systems and do proofs in Hoare-Logic style \cite{actorservice, parthasarathy2018modular}.
However, these logical frameworks have yet proven to be practical nor integrated into some existing program verification tools.
On the other hand, there are only limited existing works adopting RV for actor-based systems.
Some existing works \cite{shafiei2020actor,lavery2017actor} use the actor model to implement RV tools.
The most relevant works we can find are \cite{cassar2015synchronous,cassar2015runtime}.
\cite{cassar2015synchronous} studied the overhead between synchronous and asynchronous monitor instrumentation for actor-based systems and proposed a hybrid instrumentation technique that can be  integrated with RV tools to provide timely detection with low runtime overhead.
\cite{cassar2015runtime} proposed a runtime adaptation technique based on an existing RV tool to dynamically react to violations detected in actor-based systems.

In our project, instead of focusing on the RV techniques specifically for actor-based systems, we emphasize how to provide an abstraction layer between the distributed application and the LTL verifiers.
We provide an expressive specification language and simple bridge interface to help users model their application domains and specify the system's properties at the same time. This specification later acts as the contract between the real system and the verifier.
We pick the actor-based system because it's a popular programming model and a clean abstraction for distributed systems.
Previous work has also shown that interesting properties about actor-based systems can be specified using an LTL-like logic \cite{actorservice, parthasarathy2018modular}.

\section{Conclusion}

TODO.

\pagebreak

\bibliographystyle{ACM-Reference-Format}
\bibliography{ltlspec-report}

\end{document}
